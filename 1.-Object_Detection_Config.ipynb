{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1.-Object_Detection_Config.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"q9B_MiRavQCI","colab_type":"text"},"source":["# **In this colab we are going to download all the nessesary files**"]},{"cell_type":"markdown","metadata":{"id":"6jEWfkTrnElA","colab_type":"text"},"source":["# **Step 1 – Check GPU configurations working properly**\n","First of all we need to check the GPU configurations working properly. For that please execute following piece of python code in the colab file."]},{"cell_type":"code","metadata":{"id":"e0okumXKmtok","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","config = tf.ConfigProto()\n","config.gpu_options.allow_growth = True\n"," \n","with tf.device('/gpu:0'):\n","  random_image_gpu = tf.random_normal((100, 100, 100, 3))\n","  net_gpu = tf.layers.conv2d(random_image_gpu, 32, 7)\n","  net_gpu = tf.reduce_sum(net_gpu)\n","   \n","sess = tf.Session(config=config)\n"," \n","try:\n","  sess.run(tf.global_variables_initializer())\n","  print('ok')\n","except tf.errors.InvalidArgumentError:\n","  print(\n","      '\\n\\nThis error most likely means that this notebook is not '\n","      'configured to use a GPU.  Change this in Notebook Settings via the '\n","      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n","  raise"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ky3yQtzVnMaQ","colab_type":"text"},"source":["# **Step 2 – Connect to the Google Drive**\n","As the next step, we need to connect our colab file to the google drive. This is because, if we going to train a new model we can save it in the google drive rather than save it in the temporary location provide by the colab. To do that, please execute following code in a new code widget on colab file. Before doing this, create a new folder in your google drive"]},{"cell_type":"code","metadata":{"id":"aLxU3VxHnNS6","colab_type":"code","colab":{}},"source":["from os.path import join\n","from google.colab import drive\n"," \n","ROOT = \"/content/drive\"\n","drive.mount(ROOT)\n","\n","# This is a custom path. 'My Drive' is the root of your google drive change accordingly\n","PROJ = \"My Drive/workshop\" \n","PROJECT_PATH = join(ROOT, PROJ)\n"," \n","#%cd ~/content \n","%cd {PROJECT_PATH}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9Pb1QM-tqrXx","colab_type":"text"},"source":["# **Step 3 – Clone the Tensorflow models repository**\n","In this step, you can clone the github folder of Tensorflow´s Object detection API. Once completed you can check those files by navigating to Google drive -> My Drive -> your/folder/route directory.\n","\n","**Note:**this might take a while\n","\n","**do it only once if the folder already has the models downloaded**"]},{"cell_type":"code","metadata":{"id":"oSYKR242qsHg","colab_type":"code","colab":{}},"source":["!git clone https://github.com/tensorflow/models.git"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XYV__bmQto5q","colab_type":"text"},"source":["# **Step 4 – Download base model**\n","\n","Download the base model into the object_detection folder\n","\n","https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\n","\n","**this has to be done only once **\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"s2EHkhBUt3DQ","colab_type":"code","colab":{}},"source":["ENV = \"models/research/object_detection\" \n","PROJECT_ENV = join(PROJECT_PATH, ENV)\n","%cd {ENV}\n","\n","import os\n","import shutil\n","import glob\n","import urllib.request\n","import tarfile\n","\n","MODEL = 'faster_rcnn_inception_v2_coco_2018_01_28'\n","#MODEL = 'ssd_mobilenet_v1_coco_2018_01_28'\n","MODEL_FILE = MODEL + '.tar.gz'\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","#http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz\n","DEST_DIR = '/content/models/research/object_detection'\n","\n","if not (os.path.exists(MODEL_FILE)):\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","os.remove(MODEL_FILE)\n","if (os.path.exists(DEST_DIR)):\n","    shutil.rmtree(DEST_DIR)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vj8xOqFcMf_Z","colab_type":"text"},"source":["# **Step 5 - Move example files from the object_detection_workshop folder**\n","\n","we will need to move the following files & folders into the object detection folder\n","(/content/drive/My Drive/workshop/models/research/object_detection)\n","\n","\n","*   Images (folder containing sample images and its anotations)\n","*   inference graph (empty folder to save our inference graph model)\n","*   training folder (folder containing the config pipeline adn labelmap)\n","*   test1 (sample image file to test the model)\n","*   xml_to_csv.py (python code to collect all anotations in one csv file)\n","*   generate_tfrecord.py (pythone code to transform the csv file into a tfrecord)\n","\n"]},{"cell_type":"code","metadata":{"id":"3Ftczh3xP625","colab_type":"code","colab":{}},"source":["from os.path import join\n","ENV = \"/models/research/object_detection\" \n","PROJECT_ENV = join(PROJECT_PATH, ENV)\n","%cd {PROJECT_ENV}\n","\n","import os\n","cwd = os.getcwd()\n","print (cwd)\n","\n","!ls"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K4EZ3mukyK0T","colab_type":"text"},"source":["# **Step 6 - Create a dataset**\n","\n","A dataset must have 2 things\n","\n","\n","1.   Mixed sample images from the objects that we want to detect\n","2.   Anotations of the images\n","\n","There are many tools that we can use to label our images, in this case we will use\n","\n","https://github.com/tzutalin/labelImg\n","\n","For windows you can download it from this link\n","\n","https://drive.google.com/file/d/1Lnju0mDLB_nKdpSo4N1YdrxLGYLy7OJm/view?usp=sharing\n","\n"]}]}