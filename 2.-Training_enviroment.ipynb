{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2.-Training_enviroment.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"EiT6qtAYB1WE","colab_type":"text"},"source":["# **With this file you will configure the enviroment to start training the object detector**"]},{"cell_type":"markdown","metadata":{"id":"_fGeVmkdfCbo","colab_type":"text"},"source":["# **1. Check that the GPU can be recognized**"]},{"cell_type":"code","metadata":{"id":"QPFJHZaVBo5V","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","config = tf.ConfigProto()\n","config.gpu_options.allow_growth = True\n"," \n","with tf.device('/gpu:0'):\n","  random_image_gpu = tf.random_normal((100, 100, 100, 3))\n","  net_gpu = tf.layers.conv2d(random_image_gpu, 32, 7)\n","  #net_gpu = tf.keras.layers.Conv2D(random_image_gpu, 32, 7)\n","  net_gpu = tf.reduce_sum(net_gpu)\n","   \n","sess = tf.Session(config=config)\n"," \n","try:\n","  sess.run(tf.global_variables_initializer())\n","  print('ok')\n","except tf.errors.InvalidArgumentError:\n","  print(\n","      '\\n\\nThis error most likely means that this notebook is not '\n","      'configured to use a GPU.  Change this in Notebook Settings via the '\n","      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n","  raise"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ufdVCdz8fJBW","colab_type":"text"},"source":["# **2. Setting up the virtual environment for tensorflow-gpu**"]},{"cell_type":"code","metadata":{"id":"wViE9dZncZi3","colab_type":"code","colab":{}},"source":["#install the nessesary libraries\n","!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b0HlD3PUfd25","colab_type":"code","colab":{}},"source":["!pip install -q Cython contextlib2 pillow lxml matplotlib pandas opencv-python"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lnm6X57iffm3","colab_type":"code","colab":{}},"source":["!pip install -q pycocotools"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B5NoC3_ufiqT","colab_type":"text"},"source":["# **3. Mount google drive and navigate to the workshop folder**"]},{"cell_type":"code","metadata":{"id":"8YuWwmCHhTDb","colab_type":"code","colab":{}},"source":["from os.path import join\n","from google.colab import drive\n","import os\n"," \n","ROOT = \"/content/drive\"\n","drive.mount(ROOT)\n","\n","# This is a custom path. 'My Drive' is the root of your google drive change accordingly\n","PROJ = \"My Drive/workshop\" \n","PROJECT_PATH = join(ROOT, PROJ)\n"," \n","#%cd ~/content \n","%cd {PROJECT_PATH}\n","\n","print (\"The current directory is:\"+os.getcwd())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vyCN1H2dgrry","colab_type":"text"},"source":["# **4. Very important add the following folders to the pythopath**\n","\n","Tensorflow Object detection API needs to call some files from the structure of the \"models\" folder, thats why we add it to the pythopath"]},{"cell_type":"code","metadata":{"id":"fLieJleDh_5J","colab_type":"code","colab":{}},"source":["import os\n","os.environ['PYTHONPATH'] += ':/content/drive/My Drive/workshop/models/:/content/drive/My Drive/workshop/models/research/:/content/drive/My Drive/workshop/models/research/slim/'\n","print(  os.environ['PYTHONPATH'])\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nTy9EtaYi6pl","colab_type":"text"},"source":["**Move to the research folder and compile the protoc files (this has to be done only once)**"]},{"cell_type":"code","metadata":{"id":"NmHGnfLmi0eP","colab_type":"code","colab":{}},"source":["#move to the research folder first \n","%cd /content/drive/My Drive/workshop/models/research\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3iCpILTthrvN","colab_type":"code","colab":{}},"source":["\n","#compiling the protoc files\n","!protoc object_detection/protos/*.proto --python_out=."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SCSQc_vjkxdV","colab_type":"code","colab":{}},"source":["#build the setup file\n","!python setup.py build"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vb99YlKqlvNE","colab_type":"code","colab":{}},"source":["#install the setup file\n","!python setup.py install"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eWmN7Jj0otzI","colab_type":"text"},"source":["# **5. Run tests**\n","We need to check if everything is running"]},{"cell_type":"code","metadata":{"id":"zsiKDtumnVQz","colab_type":"code","colab":{}},"source":["#The current directory should be:/content/drive/My Drive/workshop/models/research\n","\n","import os\n","cwd = os.getcwd()\n","print (\"The current directory is:\"+cwd)\n","\n","#Change the folder if not\n","#!cd '/content/drive/My Drive/workshop/models/research'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ihqwP0Lnk_H","colab_type":"code","colab":{}},"source":["\n","!python object_detection/builders/model_builder_test.py\n","\n","#if the tests fail check the pythopath\n","# ModuleNotFoundError: No module named 'nets' => check pythopath\n","\n","#if ModuleNotFoundError: No module named 'object_detection' =>  run setup and build again"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HQCNor5HjABd","colab_type":"text"},"source":["# **6. Prepare the training configuration**"]},{"cell_type":"markdown","metadata":{"id":"DZ0n9zURozHD","colab_type":"text"},"source":["**Create CSV files from the xml anotations**"]},{"cell_type":"code","metadata":{"id":"srmNw4v6o9jX","colab_type":"code","colab":{}},"source":["#make sure you are in object detection folder\n","\n","print(os.getcwd())\n","\n","#if not change\n","#%cd object_detection/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XiO7iM7OpfDf","colab_type":"code","colab":{}},"source":["!python xml_to_csv.py"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sVgCRxuPqrt7","colab_type":"text"},"source":[" **Generate TFrecord Files**\n","\n","modify the \"generate_tfrecord.py\" file with the corresponding class labels in line 30\n"]},{"cell_type":"code","metadata":{"id":"TxtTNRZUqxnj","colab_type":"code","colab":{}},"source":["#generate tfrecord for training data\n","!python generate_tfrecord.py --csv_input=images/train_labels.csv --image_dir=images/train --output_path=train.record"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"j7-8Bcp-q15W","colab_type":"code","colab":{}},"source":["#generate tfrecord for test data\n","!python generate_tfrecord.py --csv_input=images/test_labels.csv --image_dir=images/test --output_path=test.record"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KeDmWwmKwjGb","colab_type":"text"},"source":[" **Configure faster_rcnn_inception_v2_pets.config file in the training folder**\n","\n","\n","1.   Line 9. Change num_classes to the number of different objects you want the classifier to detect. For the above example, it would be num_classes : 6 .\n","\n","2.   Line 106. Change fine_tune_checkpoint to:\n","        fine_tune_checkpoint : \"./faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt\n","\n","3.   Line 113. Change num_steps to:\n","num_steps: 10000\n","\n","4.   Lines 123 and 125. In the train_input_reader section, change input_path and label_map_path to:\n","        123 - input_path : \"./train.record\"\n","        125 - label_map_path: \"./training/labelmap.pbtxt\"\n","\n","5.   Line 130. Change num_examples to the number of images you have in the \\images\\test directory.\n","\n","6.   Lines 135 and 137. In the eval_input_reader section, change input_path and label_map_path to:\n","        input_path : \"./test.record\" \n","        label_map_path: \"./training/labelmap.pbtxt\"\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"MwYqZ9Abldsv","colab_type":"text"},"source":["**Create and configure labelmap.pbtxt in workshop/models/research/training/**"]},{"cell_type":"code","metadata":{"id":"cUF-eO_tmAJy","colab_type":"code","colab":{}},"source":["with open('training/labelmap.pbtxt', 'w') as f:\n","  f.write(\"item {\"+'\\n'+\n","            '\\t'+\"id: 1\"+'\\n'+\n","            '\\t'+\"name: 'nine'\"+'\\n'+\n","          \"}\"+'\\n'+\n","\n","          \"item {\"+'\\n'+\n","            '\\t'+\"id: 2\"+'\\n'+\n","            '\\t'+\"name: 'ten'\"+'\\n'+\n","          \"}\"+'\\n'+\n","\n","          \"item {\"+'\\n'+\n","            '\\t'+\"id: 3\"+'\\n'+\n","            '\\t'+\"name: 'jack'\"+'\\n'+\n","          \"}\"+'\\n'+\n","\n","          \"item {\"+'\\n'+\n","            '\\t'+\"id: 4\"+'\\n'+\n","            '\\t'+\"name: 'queen'\"+'\\n'+\n","          \"}\"+'\\n'+\n","\n","          \"item {\"+'\\n'+\n","            '\\t'+\"id: 5\"+'\\n'+\n","            '\\t'+\"name: 'king'\"+'\\n'+\n","          \"}\"+'\\n'+\n","\n","          \"item {\"+'\\n'+\n","            '\\t'+\"id: 6\"+'\\n'+\n","            '\\t'+\"name: 'ace'\"+'\\n'+\n","          \"}\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zGZh8RWYnYwX","colab_type":"code","colab":{}},"source":["!cat 'training/labelmap.pbtxt'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IKP2FkTnrO3r","colab_type":"text"},"source":["\n","\n","# **Move train.py from object_detection/legacy folder one up to /object_detection**"]},{"cell_type":"markdown","metadata":{"id":"hv9CuqC8qtjS","colab_type":"text"},"source":["# **7. Now we train!!!!**"]},{"cell_type":"markdown","metadata":{"id":"EmKJK0uRjrnu","colab_type":"text"},"source":["**Prepare a Tensorboard** (optional)"]},{"cell_type":"markdown","metadata":{"id":"rAI3HwL0WZXW","colab_type":"text"},"source":["\n","\n","Tensorboard is a GUI to show the advance of our trainig "]},{"cell_type":"code","metadata":{"id":"_lc8K2lZWi11","colab_type":"code","colab":{}},"source":["!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip -o ngrok-stable-linux-amd64.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zhp4yyqhWj_S","colab_type":"code","colab":{}},"source":["model_dir = 'training/'\n","LOG_DIR = model_dir\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zst9u0pxWpGA","colab_type":"code","colab":{}},"source":["get_ipython().system_raw('./ngrok http 6006 &')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jeryMD2LWtHw","colab_type":"text"},"source":["Get tensorboard link"]},{"cell_type":"code","metadata":{"id":"czeRRheaWxXl","colab_type":"code","colab":{}},"source":["! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bF019SHHk-H6","colab_type":"text"},"source":["**Make sure you are in the object detection folder**"]},{"cell_type":"code","metadata":{"id":"6Qtkt31bwoUK","colab_type":"code","colab":{}},"source":["print(os.getcwd())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WbnohsUsifjg","colab_type":"code","colab":{}},"source":["#if not, move accordingly\n","#%cd object_detection/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YHihcn1CwxLH","colab_type":"code","colab":{}},"source":["#run the training and keep this window open until getting the desired loss (ex 0.01)\n","!python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/faster_rcnn_inception_v2_pets.config"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aZdumkqStqkH","colab_type":"code","colab":{}},"source":["#once the trainig is done create a frozen_inference_graph file to do the predictions in the notebook\n","#change the checkpoint to the last one registered\n","!python export_inference_graph.py --input_type image_tensor --pipeline_config_path training/faster_rcnn_inception_v2_pets.config --trained_checkpoint_prefix training/model.ckpt-3312 --output_directory inference_graph"],"execution_count":0,"outputs":[]}]}